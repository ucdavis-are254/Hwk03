{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 03\n",
    "\n",
    "This model is based on the one we have been examining in class. \n",
    "\n",
    "$$\n",
    "v(k) = \\max_{f(k) \\geq k' \\geq 0} u(f(k) - k') + \\beta v(k')\n",
    "$$\n",
    "\n",
    "# Instructions\n",
    "\n",
    "## Part 1, due Monday\n",
    "\n",
    "1. Derive the analytic values for the value and policy functions when $f(k) = Ak^\\alpha$ instead of $f(k) = k^\\alpha$\n",
    "2. Suppose that we have a finite-horizon model that ends in period $t=T$. What must $k_{T+1}$ be? Why?\n",
    "3. In the `SimpleGrowthModel` below, I have implemented the following production function: $f(k) = k^\\alpha$\n",
    "    \n",
    "    Now create a new type, `GrowthModel <: AbstractDeterministicGrowthModel` that implements allowing a new \"technology\" parameter\n",
    "    $$\n",
    "    f(k) = Ak^\\alpha\n",
    "    $$\n",
    "4. Create functions to ouptut utility, production, kstar, cstar, and vstar\n",
    "5. Start with initial guess $V^T=0$. Now compute and plot $V^{T-i} \\gets (Tv^{T-(i-1)})(k)$ for $i \\in \\{0,1,2,3,\\ldots,10,15,20,25,50,100,200,300,400,500 \\}$ and plot. What happens as $i$ increases?\n",
    "6. Try this for  $\\beta \\in \\{0.0, 0.01, 0.1, 0.5, 0.9, 0.99, 1.0\\}$. What's different as $\\beta$ changes?\n",
    "7. Plot the optimal policy function $k' = g(k)$ for $\\beta \\in \\{0.0, 0.01, 0.1, 0.5, 0.9, 0.99, 1.0\\}$, along with the 45 degree line. What changes as $\\beta$ changes? Why?\n",
    "\n",
    "## Part 2, due Wednesday\n",
    "\n",
    "Suppose that agents can choose an action $y \\in \\{0,1\\}$. The payoffs to each are\n",
    "\\begin{align*}\n",
    "u_0(X,\\epsilon) &= \\epsilon_{i0} \\\\\n",
    "u_1(X,\\epsilon) &= x_i^\\top \\beta + \\epsilon_{i1}\n",
    "\\end{align*}\n",
    "The shocks $\\epsilon_{i0},\\epsilon_{i1}$ are distributed as iid Type-I extreme value with mean 0 and scale parameter 1. Agents choose $y_i=1$ if $u_1 \\geq u_0$ and $y_0$ if $u_1 < u_0$\n",
    "\n",
    "I have simulated $X$ and $y$ below. \n",
    "\n",
    "1. Write down the log likelihood function for each individual $i$, $\\log L_i(y_i|X_i)$ and the score $\\nabla_\\beta \\log L_i(y_i|X_i)$. Feel free to consult Greene\n",
    "2. Write a function to compute the log likelihood of the data: $\\sum_i \\log L_i(y_i|X_i)$ and the gradient of this function.\n",
    "3. Use the finite difference capabilities of `Calculus.jl` to check your gradient and make sure that it's correct\n",
    "4. Maximize the likelihood and compute standard errors using the Information Matrix. These should be\n",
    "\n",
    "    $$\n",
    "    \\left[\\sum_i \\nabla \\log L_i \\nabla \\log L_i^\\top\\right]^{-1} \\to Var(\\beta)\n",
    "    $$\n",
    "    \n",
    "    Greene ch 21 (5th ed) has the appropriate formulas\n",
    "    \n",
    "You might be able to make good use of the following functions from [`StatsFuns.jl`](https://github.com/JuliaStats/StatsFuns.jl)\n",
    "\n",
    "```julia\n",
    "logsumexp      # log(exp(x) + exp(y)) or log(sum(exp(x)))\n",
    "softmax        # exp(x_i) / sum(exp(x)), for i\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "gr(fmt = :png);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a heirarchy of abstract types in case we want to\n",
    "# recycle functions\n",
    "abstract type AbstractDeterministicGrowthModel end\n",
    "\n",
    "# create a new \"type\"\n",
    "struct SimpleGrowthModel <: AbstractDeterministicGrowthModel\n",
    "    α::Float64  # capital share\n",
    "    β::Float64  # discount rate\n",
    "end\n",
    "\n",
    "struct GrowthModel <: AbstractDeterministicGrowthModel\n",
    "   # fill in parameters!! \n",
    "end\n",
    "\n",
    "# when we create a type, it's best to access fields via functions\n",
    "_α(x::AbstractDeterministicGrowthModel) = x.α\n",
    "_β(x::AbstractDeterministicGrowthModel) = x.β\n",
    "_αβ(g::AbstractDeterministicGrowthModel) = _α(g) * _β(g)\n",
    "\n",
    "_A(g::GrowthModel) = 0.0 # FIXME\n",
    "\n",
    "# create a default constructor in case we don't supply arguments\n",
    "SimpleGrowthModel() = SimpleGrowthModel(0.65, 0.95);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new instance of a model\n",
    "SimpleGrowthModel(0.5, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct payoffs and production functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you'll need to make a new production function\n",
    "production(model::SimpleGrowthModel, k) = k^_α(model)\n",
    "\n",
    "# but you won't need to change these\n",
    "consumption(model::AbstractDeterministicGrowthModel, k, kp) = production(model, k) - kp\n",
    "utility(    model::AbstractDeterministicGrowthModel, k, kp) = log(max(consumption(model, k, kp), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create analytic solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpstar(model::SimpleGrowthModel,k) = _αβ(model) * production(model,k)\n",
    "\n",
    "cstar(model::SimpleGrowthModel,k) = (1-_αβ(model)) * production(model,k)\n",
    "\n",
    "function vfstar(model::SimpleGrowthModel, k)\n",
    "    ab = _αβ(model)\n",
    "    A = (log(1 - ab) + log(ab) * ab / (1 - ab)) / (1 - _β(model))\n",
    "    B = _α(model) / (1 - ab)\n",
    "    return A + B * log(k)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot analytidc solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of points in state-space grid\n",
    "numk = 50\n",
    "\n",
    "# state space\n",
    "k_space = range(0.01, 0.5, length=numk)\n",
    "\n",
    "g = SimpleGrowthModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vftrue = broadcast(k -> vfstar(g,k), k_space)\n",
    "kptrue = broadcast(k -> kpstar(g,k), k_space);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot true policy function\n",
    "plot_pftrue = plot(\n",
    "    k_space, hcat(k_space, kptrue);\n",
    "    labels = [\"\\$k'=k\\$\", \"\\$k^{'*}(k)\\$\"],\n",
    "    xlabel=\"\\$k_t\\$\",\n",
    "    ylabel=\"\\$k_{t+1}\\$\",\n",
    "    title=\"Policy function\",\n",
    "    legend=false\n",
    ")\n",
    "\n",
    "# plot true value function\n",
    "plot_vftrue = plot(\n",
    "    k_space, vftrue;\n",
    "    title=\"Value function\",\n",
    "    xlabel = \"\\$k\\$\",\n",
    "    legend=false\n",
    ")\n",
    "\n",
    "plot(plot_pftrue, plot_vftrue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Bellman operator\n",
    "\n",
    "$$\n",
    "(Tv)(k) = \\max_{k' \\in \\Gamma(k)} \\{u(k,k') + \\beta v(k')  \\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bellman operator with in-place updating\n",
    "function bellman!(vf1, pf1, model::AbstractDeterministicGrowthModel, vf0, state_space)\n",
    "\n",
    "    # defensive programming!\n",
    "    size(vf1) == size(pf1) == size(vf0) || throw(DimensionMismatch())\n",
    "    length(state_space) == length(vf1) || throw(DimensionMismatch())\n",
    "\n",
    "    # for each possible state today\n",
    "    for (i,k) in enumerate(state_space)\n",
    "               \n",
    "        # given the state, check each possible action and pick the optimal one\n",
    "        # in general, we'll need to be more careful about how actions map to states in t+1\n",
    "        kp_space = state_space\n",
    "        \n",
    "        # payoff today (return) given choice of kprime\n",
    "        f(kp) = utility(model, k, kp)\n",
    "\n",
    "        # pick the best kp given the static + dynamic payoff\n",
    "        vf1[i], pf1[i] = findmax(f.(kp_space) .+ _β(g) .* vf0)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "# without in-place updating\n",
    "function bellman(model, vf0, state_space)\n",
    "    vf1 = similar(vf0)\n",
    "    pf1 = Array{Int}(undef, size(vf0))\n",
    "    bellman!(vf1, pf1, model, vf0, state_space)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with Bellman operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf0 = zeros(numk)\n",
    "vf1 = similar(vf0)\n",
    "pf = Vector{Int}(undef, numk)\n",
    "\n",
    "pltv = plot(k_space, vf0, color = :black, linewidth = 2, alpha = 0.8, lab=\"\")\n",
    "\n",
    "# create new instance of a model\n",
    "g = SimpleGrowthModel()\n",
    "\n",
    "maxit = 5\n",
    "for i in 1:maxit\n",
    "    # Do one iteration\n",
    "    bellman!(vf1, pf, g, vf0, k_space)\n",
    "    \n",
    "    # update vf1\n",
    "    vf0 .= vf1\n",
    "    \n",
    "    # plot iteration\n",
    "    plot!(pltv, k_space, vf1, color = RGBA(i/maxit, 0, 1 - i/maxit, 0.8), linewidth = 2, alpha = 0.6, lab=\"\")\n",
    "    \n",
    "end\n",
    "\n",
    "plot!(pltv, k_space, (x)->0.0, color = :black, linewidth = 2, alpha = 0.8, lab=\"\\$V^T\\$\")\n",
    "plot!(pltv, k_space, vftrue, color = :black, linewidth = 2, alpha = 0.8, lab = \"\\$\\\\hat V = V^{T-\\\\infty}\\$\")\n",
    "plot!(pltv, legend = :right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "using StatsFuns\n",
    "using Optim\n",
    "using LinearAlgebra\n",
    "using Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(1234)\n",
    "\n",
    "nobs = 100\n",
    "β = [1.0, -2.0, 1.0, 2.0]\n",
    "k = length(β)\n",
    "X = randn(nobs, k)\n",
    "\n",
    "# choice utilities\n",
    "u0 = zeros(nobs)\n",
    "u1 = X*β\n",
    "u = hcat(u0, u1)\n",
    "\n",
    "# multinomial logit probabilities\n",
    "prob_actions = mapslices(softmax, u; dims=2)\n",
    "cum_prob = cumsum(prob_actions; dims=2)\n",
    "@assert all(cum_prob[:,2] .≈ 1)\n",
    "\n",
    "# instead of simulating random type-1 extreme values, we just\n",
    "# use a uniform variable and the CDF\n",
    "e_quantile = rand(nobs)\n",
    "y = [searchsortedfirst(view(cum_prob, i, :), q) for (i,q) in enumerate(e_quantile) ] .- 1 ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn!\n",
    "\n",
    "You can probably just fill these functions in. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function checksizes(y,X,theta)\n",
    "    n,k = size(X)\n",
    "    n == length(y) || throw(DimensionMismatch())\n",
    "    k == length(theta) || throw(DimensionMismatch())\n",
    "    return n, k\n",
    "end\n",
    "\n",
    "function loglik(y::AbstractVector{Int}, X::AbstractMatrix, theta::AbstractVector)\n",
    "    n,k = checksizes(y,X,theta)\n",
    "\n",
    "    # compute log likelihood\n",
    "    \n",
    "    return -LL  # I *think* you'll need to flip sign to maximize\n",
    "end\n",
    "\n",
    "\n",
    "function dloglik!(grad::AbstractVector, y::AbstractVector{Int}, X::AbstractMatrix, theta::AbstractVector)\n",
    "    n,k = checksizes(y,X,theta)    \n",
    "    k == length(grad) || throw(DimensionMismatch())\n",
    "    \n",
    "    # compute gradient\n",
    "    \n",
    "    grad .*= -1  # flip signs to \n",
    "    return grad\n",
    "end\n",
    "\n",
    "dloglik(y::AbstractVector{Int}, X::AbstractMatrix, theta::AbstractVector) = dloglik!(similar(theta), y, X, theta)\n",
    "\n",
    "function informationmatrix(y::AbstractVector{Int}, X::AbstractMatrix, theta::AbstractVector)\n",
    "    n,k = checksizes(y,X,theta)    \n",
    "    infomatrix = zeros(k,k)\n",
    "    for i in 1:n\n",
    "       infomatrix .+= 0 # FIXME\n",
    "    end\n",
    "    return -infomatrix # maybe flip signs?\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some wrappers\n",
    "theta0 = zeros(k)\n",
    "\n",
    "f(thet) = loglik(y,X,thet)\n",
    "\n",
    "g!(grad,thet) = dloglik!(grad,y,X,thet)\n",
    "\n",
    "\n",
    "# Check your gradients\n",
    "@assert Calculus.gradient(f, theta0) ≈ dloglik(y,X,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show results = optimize(f, g!, theta0, BFGS(); show_trace=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1 = results.minimizer  # should be about β\n",
    "Vcovinv = informationmatrix(y, X, theta1)\n",
    "stderr = sqrt(diag(inv(Vcovinv)))\n",
    "pvalues = 0.0 # your turn to figure out this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
